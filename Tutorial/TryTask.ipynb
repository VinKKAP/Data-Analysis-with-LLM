{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/VinKKAP/Data-Analysis-with-LLM/blob/main/TryTask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kuyagNmx8wVD",
    "outputId": "a78a1c63-87ef-4e4b-ffc2-573d0e65943e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\kappv\\anaconda3\\lib\\site-packages (24.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in c:\\users\\kappv\\anaconda3\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: transformers in c:\\users\\kappv\\anaconda3\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Upgrade pip und installiere die benötigten Pakete\n",
    "%pip install --upgrade pip\n",
    "%pip install --upgrade torch transformers\n",
    "import torch\n",
    "\n",
    "#from google.colab import userdata\n",
    "#userdata.get('HF_TOKEN')\n",
    "\n",
    "# Überprüfen, ob CUDA verfügbar ist, und den Namen des CUDA-Geräts abrufen\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hCHKwoosOk1k",
    "outputId": "7801d712-97f1-49e4-8fdb-4aa266904746"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6sfyFhJCqPK"
   },
   "source": [
    "GPU ist verbunden für die berechnung, aber die\n",
    "\n",
    "1.   Listeneintrag\n",
    "2.   Listeneintrag\n",
    "\n",
    "Instruction für das Modell scheitert daran das dass jeweilige Modell nicht richtig im Code aus dem Buch funktioniert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wnyH8nmrq_20"
   },
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cBTB_x9hq86I",
    "outputId": "b0157320-d100-4a81-bcba-3725bd081aae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(':memory:')\n",
    "\n",
    "version = sqlite3.version\n",
    "print(version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzrgjVw_CpxD",
    "outputId": "e120a550-0e59-411d-c44e-ed85bb261f70"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfd54d3a41747928f501560430856f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312091db33ad4440b750d66a29a9f1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3009a48ff86040bc9768fb1803268e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ae7d193b8f4bb59a1dc0c38b30dea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd46e8f31e9644d896a991c6de405db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46ea50b81324b49bce0f13d680ea763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528049ef8be3405a8c21452263b0611f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL: SELECT name FROM games ORDER BY americasales DESC LIMIT 10;\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "import torch\n",
    "import re\n",
    "import time\n",
    "from transformers import pipeline\n",
    "\n",
    "def create_prompt(question):  #1\n",
    "    \"\"\" Generate prompt to translate question into SQL query.\n",
    "\n",
    "    Args:\n",
    "        question: question about data in natural language.\n",
    "\n",
    "    Returns:\n",
    "        prompt for question translation.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    parts += ['Database:']\n",
    "    parts += ['create table games(rank int, name text, platform text,']\n",
    "    parts += ['year int, genre text, publisher text, americasales numeric,']\n",
    "    parts += ['eusales numeric, japansales numeric, othersales numeric,']\n",
    "    parts += ['globalsales numeric);']\n",
    "    parts += ['Translate this question into SQL query:']\n",
    "    parts += [question]\n",
    "    return '\\n'.join(parts)\n",
    "\n",
    "def call_llm(prompt):  #2\n",
    "    \"\"\" Query large language model and return answer.\n",
    "\n",
    "    Args:\n",
    "        prompt: input prompt for language model.\n",
    "\n",
    "    Returns:\n",
    "        Answer by language model.\n",
    "    \"\"\"\n",
    "    pipe = pipeline(\"text-generation\", model=\"Qwen/Qwen2-1.5B-Instruct\", max_length=600, device=device, truncation=True)\n",
    "    for nr_retries in range(1, 4):\n",
    "        try:\n",
    "            response = pipe(prompt, max_length=100)\n",
    "            return response[0]['generated_text']\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            time.sleep(nr_retries * 2)\n",
    "    raise Exception('Cannot query model!')\n",
    "\n",
    "if __name__ == '__main__':  #3\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('question', type=str, help='A question about games')\n",
    "    args = parser.parse_args(['What are the most sold games?'])\n",
    "\n",
    "    prompt = create_prompt(args.question)\n",
    "    answer = call_llm(prompt) #4\n",
    "    query = re.findall(r'SELECT.*?;', answer, re.DOTALL)\n",
    "    if query:\n",
    "        print(f'SQL: {query[0]}')\n",
    "    else:\n",
    "        print(\"No SQL query found in the response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ZG3ySOZuhfA",
    "outputId": "39eb9667-6f38-4181-ef3f-ab8749162426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database:\n",
      "create table games(rank int, name text, platform text,\n",
      "year int, genre text, publisher text, americasales numeric,\n",
      "eusales numeric, japansales numeric, othersales numeric,\n",
      "globalsales numeric);\n",
      "Translate this question into SQL query:\n",
      "What are the most sold games?\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7h7NbS6fuolT",
    "outputId": "0ebcaf26-c935-407b-ca92-f701dd64a5a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database:\n",
      "create table games(rank int, name text, platform text,\n",
      "year int, genre text, publisher text, americasales numeric,\n",
      "eusales numeric, japansales numeric, othersales numeric,\n",
      "globalsales numeric);\n",
      "Translate this question into SQL query:\n",
      "What are the most sold games? SELECT name FROM games ORDER BY americasales DESC LIMIT 10;\n",
      "Here is the SQL code to get the most sold games. It orders all the games by their Americas sales in descending order and then\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oismKH5RjV6O",
    "outputId": "4dc4bcaf-47db-4d31-844c-beb251988b29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'user',\n",
       "    'content': 'Database:\\ncreate table games(rank int, name text, platform text,\\nyear int, genre text, publisher text, americasales numeric,\\neusales numeric, japansales numeric, othersales numeric,\\nglobalsales numeric);\\nTranslate this question into SQL query:\\nWhat are the most sold games?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'To find the most sold games, you can use the following SQL query:\\n\\n```\\nSELECT name, globalsales \\nFROM games \\nORDER BY globalsales DESC \\nLIMIT 1;\\n```\\n\\nThis query selects the `name` and `globalsales` columns from the `games` table, orders them in descending order by `globalsales`, and then limits the result to only one row, which represents the game with the highest sales.'}]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "messages = [\n",
    "\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "\n",
    "           ]\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"Qwen/Qwen2-1.5B-Instruct\", max_length=900, device='cuda')\n",
    "\n",
    "pipe(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tp-oJFsYr4Y3"
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('games.db')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL: \n",
      "SELECT COUNT(*) FROM games WHERE year = 2017;\n",
      "```\n",
      "\n",
      "This query selects all rows from the `games` table where the `year` column is equal to 2017. The `COUNT(*)` function then counts the number of matches found and returns that count as the result. If you want to display the results only for the first game in 2017 (assuming there's at least one), you could modify the query like so:\n",
      "\n",
      "```sql\n",
      "SELECT * FROM games WHERE year = 2017 LIMIT 1;\n",
      "``` \n",
      "\n",
      "This will return the first row of data in the `games` table where the `year` column equals 2017. If there are no such records, it will return nothing. \n",
      "\n",
      "Remember to replace `games`, `rank`, `name`, etc., with your actual table and column names if they're different. Also, adjust the logic according to whether you need to include the global sales or not. If you only care about Americasales, EUSales, JapanSales, Othersales, and GlobalSales, you might want to select those instead of just `globalsales`. Similarly, if you only care about a specific game, you would need to specify its index directly rather than using the wildcard `%`. For example, to select only the first game in 2017:\n",
      "\n",
      "```sql\n",
      "SELECT * FROM games WHERE year = 2017 AND rank = 1;\n",
      "\n",
      "Error processing query! Try to reformulate.\n",
      "SQL: \n",
      "SELECT COUNT(*) \n",
      "FROM games \n",
      "WHERE year = 2017;\n",
      "```\n",
      "\n",
      "This query selects the count of all rows where the 'year' column equals 2017. The `COUNT(*)` function returns the number of records that match the specified condition. If you want to retrieve specific columns from the game table instead of counting them, you would need to modify the SELECT clause accordingly. For example, if you only wanted the game names and years, you could use:\n",
      "\n",
      "```sql\n",
      "SELECT name, year \n",
      "FROM games \n",
      "WHERE year = 2017;\n",
      "\n",
      "Error processing query! Try to reformulate.\n",
      "SQL: \n",
      "SELECT COUNT(*) FROM games WHERE year = 2015;\n",
      "\n",
      "Error processing query! Try to reformulate.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import re\n",
    "import time\n",
    "from transformers import pipeline\n",
    "import sqlite3\n",
    "import sys\n",
    "\n",
    "# Connect to the database\n",
    "#conn = sqlite3.connect('games.db')\n",
    "#cursor = conn.cursor()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_structure(data_path): #1 Extracts the database structure\n",
    "    \"\"\" Extract structure from SQLite database.\n",
    "\n",
    "    Args:\n",
    "        data_path: path to SQLite data file.\n",
    "\n",
    "    Returns:\n",
    "        text description of database structure.\n",
    "    \"\"\"\n",
    "    with sqlite3.connect(data_path) as connection:\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"select sql from sqlite_master where type = 'table';\")\n",
    "        table_rows = cursor.fetchall()\n",
    "        table_ddls = [r[0] for r in table_rows]\n",
    "    return '\\n'.join(table_ddls)\n",
    "\n",
    "def create_prompt(description, question): #2 Creates a prompt for translation\n",
    "    \"\"\" Generate prompt to translate a question into an SQL query.\n",
    "\n",
    "    Args:\n",
    "        description: text description of database structure.\n",
    "        question: question about data in natural language.\n",
    "\n",
    "    Returns:\n",
    "        prompt for question translation.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    parts += ['Database:']\n",
    "    parts += [description]\n",
    "    parts += ['Translate this question into SQL query:']\n",
    "    parts += [question]\n",
    "    return '\\n'.join(parts)\n",
    "\n",
    "def call_llm(prompt): #3 Invokes the language model\n",
    "    \"\"\" Query large language model and return answer.\n",
    "\n",
    "    Args:\n",
    "        prompt: input prompt for language model.\n",
    "\n",
    "    Returns:\n",
    "        Answer by language model.\n",
    "    \"\"\"\n",
    "    pipe = pipeline(\"text-generation\", model=\"Qwen/Qwen2-1.5B-Instruct\", max_length=800, device=device, truncation=True, temperature=0.7)\n",
    "    \n",
    "    for nr_retries in range(1, 4):\n",
    "        try:\n",
    "            response = pipe(prompt, max_length=800)\n",
    "            return response[0]['generated_text']\n",
    "        except:\n",
    "            time.sleep(nr_retries * 2)\n",
    "    raise Exception('Cannot query model!')\n",
    "\n",
    "def process_query(data_path, query): #4 Processes a query on a database\n",
    "    \"\"\" Processes SQL query and returns result.\n",
    "\n",
    "    Args:\n",
    "        data_path: path to SQLite data file.\n",
    "        query: process this query on database.\n",
    "\n",
    "    Returns:\n",
    "        query result.\n",
    "    \"\"\"\n",
    "    with sqlite3.connect(data_path) as connection:\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        table_rows = cursor.fetchall()\n",
    "        table_strings = [str(r) for r in table_rows]\n",
    "        return '\\n'.join(table_strings)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Simulate command-line arguments\n",
    "    #sys.argv = ['ipykernel_launcher.py', r'C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-3\\games.db']\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('dbpath', type=str, help='Path to SQLite data')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    data_structure = get_structure(args.dbpath) #5 Reads data structure\n",
    "    while True: #6  Answers questions until the user quits\n",
    "        user_input = input('Enter question:')\n",
    "        if user_input == 'quit':\n",
    "            break\n",
    "        prompt = create_prompt(data_structure, user_input)\n",
    "        answer = call_llm(prompt)\n",
    "        query = re.findall('```sql(.*)```', answer, re.DOTALL)[0]\n",
    "        print(f'SQL: {query}')\n",
    "\n",
    "        try: #7  Processes query on the database\n",
    "            result = process_query(args.data_path, query)\n",
    "            print(f'Result: {result}')\n",
    "        except:\n",
    "            print('Error processing query! Try to reformulate.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: Database:\n",
      "CREATE TABLE games(\n",
      "    rank int, \n",
      "    name text, \n",
      "    platform text,\n",
      "    year int, \n",
      "    genre text, \n",
      "    publisher text, \n",
      "    americasales numeric,\n",
      "    eusales numeric, \n",
      "    japansales numeric, \n",
      "    othersales numeric,\n",
      "    globalsales numeric\n",
      ")\n",
      "Translate this question into SQL query:\n",
      "How many games in japan have been sold more than 5000 copies? SELECT COUNT(*) FROM games WHERE country = 'Japan' AND sales > 5000; This is a straightforward SQL query that counts the number of games in Japan with sales greater than 5000. The table has columns for 'rank', 'name', 'platform', 'year', 'genre', 'publisher', 'americasales', 'eusales', 'japansales', 'othersales', and 'globalsales'. The query selects all rows where the 'country' column is equal to 'Japan' and the'sales' column is greater than 5000, then returns the count of these rows as the result. The answer will be the number of games meeting both criteria. \n",
      "\n",
      "Please note: This assumes the data is stored in a database named 'games' and follows the naming conventions used above (for example, the column names are 'rank', 'name', etc.). If there's any difference from this, please provide details so I can adjust accordingly. Also, make sure your database is set up correctly and the 'platform' field is not null or empty. It would be helpful if you could confirm what your actual schema looks like. If it's different, we'll need to adjust the query accordingly. \n",
      "\n",
      "Remember, SQL is designed to work on structured tabular data, so it doesn't automatically support complex joins or aggregations. So, if you want to filter based on multiple conditions (like here), you might need to use subqueries or other advanced SQL techniques. Always verify that the fields/columns match exactly how they appear in your database. For instance, the 'platform' column should ideally contain a value indicating which platform the game was released on. If it isn't, you may need to modify the query to account for this. Let me know if you need help with anything else!\n"
     ]
    }
   ],
   "source": [
    "print(\"LLM Response:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No SQL query found in the response.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m     query \u001b[38;5;241m=\u001b[39m query[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo SQL query found in the response.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: No SQL query found in the response."
     ]
    }
   ],
   "source": [
    "query = re.findall(r'```sql\\s*(.*?)\\s*```', answer, re.DOTALL)\n",
    "if query:\n",
    "    query = query[0]\n",
    "else:\n",
    "    raise ValueError(\"No SQL query found in the response.\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
