{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\kappv\\anaconda3\\lib\\site-packages (24.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in c:\\users\\kappv\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\kappv\\anaconda3\\lib\\site-packages (4.47.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.4/10.1 MB 13.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.2/10.1 MB 13.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.9/10.1 MB 13.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.1 MB 13.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 11.5 MB/s eta 0:00:00\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.47.0\n",
      "    Uninstalling transformers-4.47.0:\n",
      "      Successfully uninstalled transformers-4.47.0\n",
      "Successfully installed transformers-4.47.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "unable to open database file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m device\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msqlite3\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m conn \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/games.db\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m version \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mversion\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(version)\n",
      "\u001b[1;31mOperationalError\u001b[0m: unable to open database file"
     ]
    }
   ],
   "source": [
    "# Upgrade pip und installiere die benötigten Pakete\n",
    "%pip install --upgrade pip\n",
    "%pip install --upgrade torch transformers\n",
    "import torch\n",
    "\n",
    "#from google.colab import userdata\n",
    "#userdata.get('HF_TOKEN')\n",
    "\n",
    "# Überprüfen, ob CUDA verfügbar ist, und den Namen des CUDA-Geräts abrufen\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('/content/games.db')\n",
    "\n",
    "version = sqlite3.version\n",
    "print(version)\n",
    "\n",
    "# ...existing code...\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import re\n",
    "import time\n",
    "from transformers import pipeline\n",
    "\n",
    "def create_prompt(question):  #1\n",
    "    \"\"\" Generate prompt to translate question into SQL query.\n",
    "\n",
    "    Args:\n",
    "        question: question about data in natural language.\n",
    "\n",
    "    Returns:\n",
    "        prompt for question translation.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    parts += ['Database:']\n",
    "    parts += ['create table games(rank int, name text, platform text,']\n",
    "    parts += ['year int, genre text, publisher text, americasales numeric,']\n",
    "    parts += ['eusales numeric, japansales numeric, othersales numeric,']\n",
    "    parts += ['globalsales numeric);']\n",
    "    parts += ['Translate this question into SQL query:']\n",
    "    parts += [question]\n",
    "    return '\\n'.join(parts)\n",
    "\n",
    "def call_llm(prompt):  #2\n",
    "    \"\"\" Query large language model and return answer.\n",
    "\n",
    "    Args:\n",
    "        prompt: input prompt for language model.\n",
    "\n",
    "    Returns:\n",
    "        Answer by language model.\n",
    "    \"\"\"\n",
    "    pipe = pipeline(\"text-generation\", model=\"Qwen/Qwen2-1.5B-Instruct\", max_length=600, device=device, truncation=True)\n",
    "    for nr_retries in range(1, 4):\n",
    "        try:\n",
    "            response = pipe(prompt, max_length=100)\n",
    "            return response[0]['generated_text']\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            time.sleep(nr_retries * 2)\n",
    "    raise Exception('Cannot query model!')\n",
    "\n",
    "if __name__ == '__main__':  #3\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('question', type=str, help='A question about games')\n",
    "    args = parser.parse_args(['How many games are stored in total'])\n",
    "\n",
    "    prompt = create_prompt(args.question)\n",
    "    answer = call_llm(prompt) #4\n",
    "    query = re.findall(r'SELECT.*?;', answer, re.DOTALL)\n",
    "    if query:\n",
    "        print(f'SQL: {query[0]}')\n",
    "    else:\n",
    "        print(\"No SQL query found in the response.\")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT SUM(games.globalsales) FROM games;\")  # Replace with query\n",
    "results = cursor.fetchall()\n",
    "print(results)\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "messages = [\n",
    "\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "\n",
    "           ]\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"Qwen/Qwen2-1.5B-Instruct\", max_length=900, device='cpu')\n",
    "\n",
    "pipe(messages)\n",
    "\n",
    "conn = sqlite3.connect('games.db')\n",
    "\n",
    "!pip install pathlib\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import re\n",
    "import time\n",
    "from transformers import pipeline\n",
    "import sqlite3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Connect to the database\n",
    "#conn = sqlite3.connect('games.db')\n",
    "#cursor = conn.cursor()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_structure(data_path): #1 Extracts the database structure\n",
    "    \"\"\" Extract structure from SQLite database.\n",
    "\n",
    "    Args:\n",
    "        data_path: path to SQLite data file.\n",
    "\n",
    "    Returns:\n",
    "        text description of database structure.\n",
    "    \"\"\"\n",
    "    with sqlite3.connect(data_path) as connection:\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"select sql from sqlite_master where type = 'table';\")\n",
    "        table_rows = cursor.fetchall()\n",
    "        table_ddls = [r[0] for r in table_rows]\n",
    "    return '\\n'.join(table_ddls)\n",
    "\n",
    "def create_prompt(description, question): #2 Creates a prompt for translation\n",
    "    \"\"\" Generate prompt to translate a question into an SQL query.\n",
    "\n",
    "    Args:\n",
    "        description: text description of database structure.\n",
    "        question: question about data in natural language.\n",
    "\n",
    "    Returns:\n",
    "        prompt for question translation.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    parts += ['Database:']\n",
    "    parts += [description]\n",
    "    parts += ['Translate this question into SQL query:']\n",
    "    parts += [question]\n",
    "    return '\\n'.join(parts)\n",
    "\n",
    "def call_llm(prompt): #3 Invokes the language model\n",
    "    \"\"\" Query large language model and return answer.\n",
    "\n",
    "    Args:\n",
    "        prompt: input prompt for language model.\n",
    "\n",
    "    Returns:\n",
    "        Answer by language model.\n",
    "    \"\"\"\n",
    "    pipe = pipeline(\"text-generation\", model=\"Qwen/Qwen2-1.5B-Instruct\", max_length=800, device=device, truncation=True, temperature=0.7)\n",
    "\n",
    "    for nr_retries in range(1, 4):\n",
    "        try:\n",
    "            response = pipe(prompt, max_length=800)\n",
    "            return response[0]['generated_text']\n",
    "        except:\n",
    "            time.sleep(nr_retries * 2)\n",
    "    raise Exception('Cannot query model!')\n",
    "\n",
    "def process_query(data_path, query): #4 Processes a query on a database\n",
    "    \"\"\" Processes SQL query and returns result.\n",
    "\n",
    "    Args:\n",
    "        data_path: path to SQLite data file.\n",
    "        query: process this query on database.\n",
    "\n",
    "    Returns:\n",
    "        query result.\n",
    "    \"\"\"\n",
    "    with sqlite3.connect(data_path) as connection:\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        table_rows = cursor.fetchall()\n",
    "        table_strings = [str(r) for r in table_rows]\n",
    "        return '\\n'.join(table_strings)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ### Simulate command-line arguments\n",
    "    ###sys.argv = ['ipykernel_launcher.py', r'C:\\\\Users\\\\kappv\\\\Desktop\\\\Data-Analysis-with-LLM-3\\\\games.db']\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('dbpath', type=str, help='Path to SQLite data')\n",
    "    # Instead of directly calling parse_args(), provide the path to the database\n",
    "    #args = parser.parse_args() # original\n",
    "    args = parser.parse_args(['games.db']) # updated call using database path\n",
    "\n",
    "    data_structure = get_structure(args.dbpath) #5 Reads data structure\n",
    "    while True: #6  Answers questions until the user quits\n",
    "        user_input = input('Enter question:')\n",
    "        if user_input == 'quit':\n",
    "            break\n",
    "        prompt = create_prompt(data_structure, user_input)\n",
    "        answer = call_llm(prompt)\n",
    "        query = re.findall('SELECT.*?;', answer, re.DOTALL)[0]\n",
    "        print(f'SQL: {query}')\n",
    "\n",
    "        try: #7  Processes query on the database\n",
    "            result = process_query(args.dbpath, query)\n",
    "            print(f'Result: {result}')\n",
    "        except:\n",
    "            print('Error processing query! Try to reformulate.')\n",
    "\n",
    "print(\"LLM Response:\", answer)\n",
    "\n",
    "query = re.findall(r'SELECT.*?;', answer, re.DOTALL)\n",
    "if query:\n",
    "    query = query[0]\n",
    "else:\n",
    "    raise ValueError(\"No SQL query found in the response.\")\n",
    "\n",
    "print(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
