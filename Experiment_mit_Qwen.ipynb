{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/VinKKAP/Data-Analysis-with-LLM/blob/main/Experiment_mit_Qwen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cC-ECJCiC5QZ",
    "outputId": "91d09fcf-f61c-4e1d-c16b-9041a4712286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "git is already the newest version (1:2.34.1-1ubuntu1.11).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z9jpnfJuDCI3",
    "outputId": "e001fbce-c6f9-488c-ec83-19bbd9fd3dd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Data-Analysis-with-LLM'...\n",
      "remote: Enumerating objects: 236, done.\u001b[K\n",
      "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
      "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
      "remote: Total 236 (delta 6), reused 9 (delta 2), pack-reused 215 (from 1)\u001b[K\n",
      "Receiving objects: 100% (236/236), 57.47 MiB | 16.00 MiB/s, done.\n",
      "Resolving deltas: 100% (75/75), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/VinKKAP/Data-Analysis-with-LLM.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fvAX46fhDG-7",
    "outputId": "c11c41cf-5de5-4019-c910-6e37d02e2fbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from -r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (2.13.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from -r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 2)) (1.5.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from -r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 3)) (3.20.3)\n",
      "Requirement already satisfied: scikit_learn in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from -r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 4)) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from -r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 5)) (1.10.1)\n",
      "Requirement already satisfied: simpletransformers in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from -r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (0.64.3)\n",
      "Requirement already satisfied: torch in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from -r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 7)) (2.5.1+cu124)\n",
      "Requirement already satisfied: transformers in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from -r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 8)) (4.46.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (14.0.2)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (0.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from fsspec[http]>=2021.11.1->datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (0.23.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from pandas->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from pandas->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 2)) (2023.3.post1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from scikit_learn->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from scikit_learn->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 4)) (2.2.0)\n",
      "Requirement already satisfied: regex in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (2023.10.3)\n",
      "Requirement already satisfied: seqeval in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (1.2.2)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (2.18.0)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (0.20.3)\n",
      "Requirement already satisfied: wandb>=0.10.32 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (0.18.5)\n",
      "Requirement already satisfied: streamlit in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (1.40.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from torch->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 7)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from torch->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 7)) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from torch->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 7)) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from torch->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 7)) (3.1.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from torch->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from transformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 8)) (0.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from aiohttp->datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from aiohttp->datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from aiohttp->datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from aiohttp->datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from aiohttp->datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (1.9.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (3.1.37)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (3.10.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (5.9.0)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (2.17.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (1.3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (68.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from jinja2->torch->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 7)) (2.1.3)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (4.2.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (10.2.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (13.3.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (8.2.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (0.10.2)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (6.3.3)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (2.1.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (1.67.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (2.2.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (4.23.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (0.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (4.0.7)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (2.15.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (4.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.14.0->streamlit->simpletransformers->-r C:\\Users\\kappv\\Desktop\\Data-Analysis-with-LLM-4\\Paper\\requirements.txt (line 6)) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r /content/Data-Analysis-with-LLM/Paper/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9LEqB1GEjdj",
    "outputId": "b3e2808f-ff3e-4952-c153-e44b06a7824f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scikit-learn, tokenizers, transformers\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.31.0\n",
      "    Uninstalling transformers-4.31.0:\n",
      "      Successfully uninstalled transformers-4.31.0\n",
      "Successfully installed scikit-learn-1.5.2 tokenizers-0.20.3 transformers-4.46.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8NFu3pzFj4m",
    "outputId": "c2b922b2-a824-4801-d433-d93b81917f72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.0.1\n",
      "Uninstalling torch-2.0.1:\n",
      "  Successfully uninstalled torch-2.0.1\n",
      "Found existing installation: transformers 4.46.3\n",
      "Uninstalling transformers-4.46.3:\n",
      "  Successfully uninstalled transformers-4.46.3\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch)\n",
      "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0\n",
      "    Uninstalling triton-2.0.0:\n",
      "      Successfully uninstalled triton-2.0.0\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.6.77\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
      "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
      "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 torch-2.5.1 transformers-4.46.3 triton-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y torch transformers\n",
    "!pip install torch transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from gdown) (4.65.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2024.8.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kappv\\anaconda3\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-5.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6tAwW3wBh7PK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache() # Removed the extra indentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8KZCUokFKwdt",
    "outputId": "505833b0-c5c7-4d64-8bd2-57fc0277398f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_recall_fscore_support\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m     24\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m userdata\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Created on Aug 12, 2023\n",
    "\n",
    "@author: immanueltrummer\n",
    "'''\n",
    "from multiprocessing import set_start_method\n",
    "try:\n",
    "    set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "import argparse\n",
    "import sklearn.metrics as metrics\n",
    "import pandas as pd\n",
    "import random as rand\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "from google.colab import userdata\n",
    "userdata.get('HF_TOKEN')\n",
    "\n",
    "def add_type(row):\n",
    "    \"\"\" Enrich column name by adding column type.\n",
    "\n",
    "    Args:\n",
    "        row: describes correlation between two columns.\n",
    "\n",
    "    Returns:\n",
    "        row with enriched column names.\n",
    "    \"\"\"\n",
    "    row['column1'] = row['column1'] + ' ' + row['type1']\n",
    "    row['column2'] = row['column2'] + ' ' + row['type2']\n",
    "    return row\n",
    "\n",
    "def def_split(data, test_ratio, seed):\n",
    "    \"\"\" Split data into training and test set.\n",
    "\n",
    "    With this approach, different column pairs from the\n",
    "    same data set may appear in training and test set.\n",
    "\n",
    "    Args:\n",
    "        data: a pandas dataframe containing all data.\n",
    "        test_ratio: ratio of test cases after split.\n",
    "        seed: random seed for deterministic results.\n",
    "\n",
    "    Returns:\n",
    "        a tuple containing training, then test data.\n",
    "    \"\"\"\n",
    "    print('Data sets in training and test may overlap')\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "      data[['column1', 'column2', 'type1', 'type2']], data['label'],\n",
    "      test_size=test_ratio, random_state=seed)\n",
    "    train = pd.concat([x_train, y_train], axis=1)\n",
    "    test = pd.concat([x_test, y_test], axis=1)\n",
    "    print(f'train shape: {train.shape}')\n",
    "    print(f'test shape: {test.shape}')\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def ds_split(data, test_ratio):\n",
    "    \"\"\" Split column pairs into training and test samples.\n",
    "\n",
    "    With this method, training and test set contain columns\n",
    "    of disjunct data sets, making prediction a bit harder.\n",
    "\n",
    "    Args:\n",
    "        data: a pandas dataframe containing all data.\n",
    "        test_ratio: ratio of test cases after splitting.\n",
    "\n",
    "    Returns:\n",
    "        a tuple containing training, then test set.\n",
    "    \"\"\"\n",
    "    print('Separating training and test sets by data')\n",
    "    counts = data['dataid'].value_counts()\n",
    "    print(f'Counts: {counts}')\n",
    "    print(f'Count.index: {counts.index}')\n",
    "    print(f'Count.index.values: {counts.index.values}')\n",
    "    print(f'counts.shape: {counts.shape}')\n",
    "    print(f'counts.iloc[0]: {counts.iloc[0]}')\n",
    "    nr_vals = len(counts)\n",
    "    nr_test_ds = int(nr_vals * test_ratio)\n",
    "    print(f'Nr. test data sets: {nr_test_ds}')\n",
    "    ds_ids = counts.index.values.tolist()\n",
    "    print(type(ds_ids))\n",
    "    print(ds_ids)\n",
    "    test_ds = rand.sample(ds_ids, nr_test_ds)\n",
    "    print(f'TestDS: {test_ds}')\n",
    "\n",
    "    def is_test(row):\n",
    "        if row['dataid'] in test_ds:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    data['istest'] = data.apply(is_test, axis=1)\n",
    "    train = data[data['istest'] == False]\n",
    "    test = data[data['istest'] == True]\n",
    "    print(f'train.shape: {train.shape}')\n",
    "    print(f'test.shape: {test.shape}')\n",
    "    print(train)\n",
    "    print(test)\n",
    "    return train[\n",
    "        ['column1', 'column2', 'type1', 'type2', 'label']], test[\n",
    "            ['column1', 'column2', 'type1', 'type2', 'label']]\n",
    "\n",
    "\n",
    "def baseline(col_pairs):\n",
    "    \"\"\" A simple baseline predicting correlation via Jaccard similarity.\n",
    "\n",
    "    Args:\n",
    "        col_pairs: list of tuples with column names.\n",
    "\n",
    "    Returns:\n",
    "        list of predictions (1 for correlation, 0 for no correlation).\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for cp in col_pairs:\n",
    "        c1 = cp[0]\n",
    "        c2= cp[1]\n",
    "        s1 = set(c1.split())\n",
    "        s2 = set(c2.split())\n",
    "        ns1 = len(s1)\n",
    "        ns2 = len(s2)\n",
    "        ni = len(set.intersection(s1, s2))\n",
    "        # calculate Jaccard coefficient\n",
    "        jac = ni / (ns1 + ns2 - ni)\n",
    "        # predict correlation if similar\n",
    "        if jac > 0.5:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# log all metrics into summary for data subset\n",
    "def log_metrics(\n",
    "        coeff, min_v1, max_v2, mod_type, mod_name, scenario,\n",
    "        test_ratio, sub_test, test_name, lb, ub, pred_method,\n",
    "        out_path, training_time):\n",
    "    \"\"\" Predicts using baseline or model, writes metrics to file.\n",
    "\n",
    "    Args:\n",
    "        coeff: predict correlation according to this coefficient.\n",
    "        min_v1: lower bound on coefficient value for correlation.\n",
    "        max_v2: upper bound on p-value to be considered correlated.\n",
    "        mod_type: base type of language model used for prediction.\n",
    "        mod_name: precise name of language model used for prediction.\n",
    "        scenario: how training and test data relate to each other.\n",
    "        test_ratio: ratio of column pairs used for testing (not training).\n",
    "        sub_test: data frame with test cases, possibly a subset.\n",
    "        test_name: write this test name into result file.\n",
    "        lb: lower bound on a test-specific metric constraining test cases.\n",
    "        ub: upper bound on test-specific metric, constraining test cases.\n",
    "        pred_method: whether to use language model or simple baseline.\n",
    "        out_path: path to result output file (results are appended).\n",
    "        training_time: time taken to train the model.\n",
    "    \"\"\"\n",
    "    sub_test.columns = [\n",
    "        'text_a', 'text_b', 'type1', 'type2', 'labels', 'length', 'nrtokens']\n",
    "    # print out a sample for later analysis\n",
    "    print(f'Sample for test {test_name}:')\n",
    "    sample = sub_test.sample(frac=0.1)\n",
    "    print(sample)\n",
    "    # predict correlation via baseline or model\n",
    "    sub_test = sub_test[['text_a', 'text_b', 'labels']]\n",
    "    samples = []\n",
    "    for _, r in sub_test.iterrows():\n",
    "        samples.append([r['text_a'], r['text_b']])\n",
    "    s_time = time.time()\n",
    "    if pred_method == 0:\n",
    "        preds = baseline(samples)\n",
    "    else:\n",
    "        preds = model.predict(samples)[0]\n",
    "    # log various performance metrics\n",
    "    t_time = time.time() - s_time\n",
    "    nr_samples = len(sub_test.index)\n",
    "    t_per_s = float(t_time) / nr_samples\n",
    "    f1 = metrics.f1_score(sub_test['labels'], preds)\n",
    "    pre = metrics.precision_score(sub_test['labels'], preds)\n",
    "    rec = metrics.recall_score(sub_test['labels'], preds)\n",
    "    acc = metrics.accuracy_score(sub_test['labels'], preds)\n",
    "    mcc = metrics.matthews_corrcoef(sub_test['labels'], preds)\n",
    "    # also log to local file\n",
    "    with open(out_path, 'a+') as file:\n",
    "        file.write(f'{coeff},{min_v1},{max_v2},\"{mod_type}\",' \\\n",
    "                f'\"{mod_name}\",\"{scenario}\",{test_ratio},' \\\n",
    "                f'\"{test_name}\",{pred_method},{lb},{ub},' \\\n",
    "                f'{f1},{pre},{rec},{acc},{mcc},{t_per_s},' \\\n",
    "                f'{training_time}\\n')\n",
    "\n",
    "\n",
    "def names_length(row):\n",
    "    \"\"\" Calculate combined length of column names.\n",
    "\n",
    "    Args:\n",
    "        row: contains information on one column pair.\n",
    "\n",
    "    Returns:\n",
    "        combined length of column names (in characters).\n",
    "    \"\"\"\n",
    "    return len(row['text_a']) + len(row['text_b'])\n",
    "\n",
    "def names_tokens(row):\n",
    "    \"\"\" Calculates number of tokens (separated by spaces).\n",
    "\n",
    "    Attention: this is not the number of tokens as calculated\n",
    "    by the tokenizer of the language model but an approximation.\n",
    "\n",
    "    Args:\n",
    "        row: contains information on one column pair.\n",
    "\n",
    "    Returns:\n",
    "        number of space-separated substrings in both column names.\n",
    "    \"\"\"\n",
    "    return row['text_a'].count(' ') + row['text_b'].count(' ')\n",
    "\n",
    "\n",
    "def run_experiment(src_path, coeff, min_v1, max_v2, mod_type, mod_name, scenario, test_ratio, use_types, out_path):\n",
    "    # print parameters\n",
    "    print(f'Coefficients: {coeff}')\n",
    "    print(f'Minimal value 1: {min_v1}')\n",
    "    print(f'Maximal value 2: {max_v2}')\n",
    "    print(f'Model type: {mod_type}')\n",
    "    print(f'Model name: {mod_name}')\n",
    "    print(f'Scenario: {scenario}')\n",
    "    print(f'Test ratio: {test_ratio}')\n",
    "\n",
    "    # initialize for deterministic results\n",
    "    seed = 42\n",
    "    rand.seed(seed)\n",
    "\n",
    "    # load data\n",
    "    data = pd.read_csv(src_path, sep=',')\n",
    "    data = data.sample(frac=1, random_state=seed)\n",
    "    data.columns = [\n",
    "        'dataid', 'datapath', 'nrrows', 'nrvals1', 'nrvals2',\n",
    "        'type1', 'type2', 'column1', 'column2', 'method',\n",
    "        'coefficient', 'pvalue', 'time']\n",
    "\n",
    "    # enrich column names if activated\n",
    "    if use_types:\n",
    "        data = data.apply(add_type, axis=1)\n",
    "\n",
    "    # Initialize the tokenizer and model from the pre-trained model name\n",
    "    tokenizer = AutoTokenizer.from_pretrained(mod_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(mod_name, num_labels=2)\n",
    "\n",
    "    # Set a padding token if not already set\n",
    "    if tokenizer.pad_token is None:\n",
    "         tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    # Update the model configuration to include the pad_token_id\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    # Check if GPU is available and set the device accordingly\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # Move the model to the GPU if available\n",
    "    model.to(device)\n",
    "\n",
    "    # filter data\n",
    "    data = data[data['method'] == coeff]\n",
    "    nr_total = len(data.index)\n",
    "    print(f'Nr. samples: {nr_total}')\n",
    "    print('Sample from filtered data:')\n",
    "    print(data.head())\n",
    "\n",
    "    # label data\n",
    "    def coefficient_label(row):\n",
    "        \"\"\" Label column pair as correlated or uncorrelated.\n",
    "\n",
    "        Args:\n",
    "            row: describes correlation between column pair.\n",
    "\n",
    "        Returns:\n",
    "            1 if correlated, 0 if not correlated.\n",
    "        \"\"\"\n",
    "        if abs(row['coefficient']) >= min_v1 and abs(row['pvalue']) <= max_v2:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    data['label'] = data.apply(coefficient_label, axis=1)\n",
    "\n",
    "    # split into test and training\n",
    "    if scenario == 'defsep':\n",
    "        train, test = def_split(data, test_ratio, seed)\n",
    "    elif scenario == 'datasep':\n",
    "        train, test = ds_split(data, test_ratio)\n",
    "    else:\n",
    "        raise ValueError(f'Undefined scenario: {scenario}')\n",
    "\n",
    "    train.columns = ['text_a', 'text_b', 'type1', 'type2', 'labels']\n",
    "    test.columns = ['text_a', 'text_b', 'type1', 'type2', 'labels']\n",
    "    print(train.head())\n",
    "    print(test.head())\n",
    "\n",
    "    # prepare dataset for transformers\n",
    "    train_encodings = tokenizer(train['text_a'].tolist(), train['text_b'].tolist(), truncation=True, padding=True)\n",
    "    test_encodings = tokenizer(test['text_a'].tolist(), test['text_b'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "    class Dataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, encodings, labels):\n",
    "            self.encodings = encodings\n",
    "            self.labels = labels\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "            return item\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "    train_dataset = Dataset(train_encodings, train['labels'].tolist())\n",
    "    test_dataset = Dataset(test_encodings, test['labels'].tolist())\n",
    "\n",
    "    # prepare training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=5,\n",
    "        per_device_train_batch_size=2,  # Reduce batch size\n",
    "        per_device_eval_batch_size=4,\n",
    "        gradient_accumulation_steps=8,  # Maintain effective batch size\n",
    "        fp16=True,  # Enable mixed-precision training\n",
    "        warmup_steps=100,  # Reduce warmup steps\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=50,  # Reduce logging frequency\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        optim=\"adamw_torch\"  # Memory-efficient optimizer\n",
    "        )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # train the model\n",
    "    s_time = time.time()\n",
    "    trainer.train()\n",
    "    training_time = time.time() - s_time\n",
    "\n",
    "    test['length'] = test.apply(names_length, axis=1)\n",
    "    test['nrtokens'] = test.apply(names_tokens, axis=1)\n",
    "\n",
    "    # Initialize result file\n",
    "    with open(out_path, 'w') as file:\n",
    "        file.write(\n",
    "            'coefficient,min_v1,max_v2,mod_type,mod_name,scenario,test_ratio,'\n",
    "            'test_name,pred_method,lb,ub,f1,precision,recall,accuracy,mcc,'\n",
    "            'prediction_time,training_time\\n')\n",
    "\n",
    "    # use simple baseline and model for prediction\n",
    "    for m in [0, 1]:\n",
    "        # use entire test set (redundant - for verification)\n",
    "        test_name = f'{m}-final'\n",
    "        log_metrics(\n",
    "            coeff, min_v1, max_v2, mod_type, mod_name, scenario,\n",
    "            test_ratio, test, test_name, 0, 'inf', m, out_path, training_time)\n",
    "\n",
    "        # test for data types\n",
    "        for type1 in ['object', 'float64', 'int64', 'bool']:\n",
    "            for type2 in ['object', 'float64', 'int64', 'bool']:\n",
    "                sub_test = test.query(f'type1==\"{type1}\" and type2==\"{type2}\"')\n",
    "                if sub_test.shape[0]:\n",
    "                    test_name = f'Types{type1}-{type2}'\n",
    "                    log_metrics(\n",
    "                        coeff, min_v1, max_v2, mod_type, mod_name, scenario,\n",
    "                        test_ratio, sub_test, test_name, -1, -1, m,\n",
    "                        out_path, training_time)\n",
    "\n",
    "        # test for different subsets\n",
    "        for q in [(0, 0.25), (0.25, 0.5), (0.5, 1)]:\n",
    "            qlb = q[0]\n",
    "            qub = q[1]\n",
    "            # column name length\n",
    "            lb = test['length'].quantile(qlb)\n",
    "            ub = test['length'].quantile(qub)\n",
    "            sub_test = test[(test['length'] >= lb) & (test['length'] <= ub)]\n",
    "            test_name = f'L{m}-{qlb}-{qub}'\n",
    "            log_metrics(\n",
    "                coeff, min_v1, max_v2, mod_type, mod_name, scenario,\n",
    "                test_ratio, sub_test, test_name, lb, ub, m, out_path, training_time)\n",
    "            # number of tokens in column names\n",
    "            lb = test['nrtokens'].quantile(qlb)\n",
    "            ub = test['nrtokens'].quantile(qub)\n",
    "            sub_test = test[(test['nrtokens'] >= lb) & (test['nrtokens'] <= ub)]\n",
    "            test_name = f'N{m}-{qlb}-{qub}'\n",
    "            log_metrics(\n",
    "                coeff, min_v1, max_v2, mod_type, mod_name, scenario,\n",
    "                test_ratio, sub_test, test_name, lb, ub, m, out_path, training_time)\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='binary')\n",
    "    acc = accuracy_score(p.label_ids, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Example usage in a Jupyter Notebook or Google Colab\n",
    "args = {\n",
    "    \"src_path\": \"/content/drive/My Drive/Colab Notebooks/Liter/correlations/correlationdata.csv\",\n",
    "    \"coeff\": \"pearson\",\n",
    "    \"min_v1\": 0.9,\n",
    "    \"max_v2\": 0.05,\n",
    "    \"mod_type\": \"Qwen\",\n",
    "    \"mod_name\": \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    \"scenario\": \"defsep\",\n",
    "    \"test_ratio\": 0.2,\n",
    "    \"use_types\": 1,\n",
    "    \"out_path\": \"/content/drive/My Drive/Colab Notebooks/Liter/correlations/models\"\n",
    "}\n",
    "\n",
    "run_experiment(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0z9nWDIdMdPQ",
    "outputId": "837754b5-dd5e-435f-ea2e-38aa3ad81e66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==1.4.0\n",
      "accelerate==1.1.1\n",
      "aiohappyeyeballs==2.4.3\n",
      "aiohttp==3.11.2\n",
      "aiosignal==1.3.1\n",
      "alabaster==1.0.0\n",
      "albucore==0.0.19\n",
      "albumentations==1.4.20\n",
      "altair==4.2.2\n",
      "annotated-types==0.7.0\n",
      "anyio==3.7.1\n",
      "argon2-cffi==23.1.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "array_record==0.5.1\n",
      "arviz==0.20.0\n",
      "astropy==6.1.6\n",
      "astropy-iers-data==0.2024.11.18.0.35.2\n",
      "astunparse==1.6.3\n",
      "async-timeout==4.0.3\n",
      "atpublic==4.1.0\n",
      "attrs==24.2.0\n",
      "audioread==3.0.1\n",
      "autograd==1.7.0\n",
      "babel==2.16.0\n",
      "backcall==0.2.0\n",
      "beautifulsoup4==4.12.3\n",
      "bigframes==1.27.0\n",
      "bigquery-magics==0.4.0\n",
      "bleach==6.2.0\n",
      "blinker==1.9.0\n",
      "blis==0.7.11\n",
      "blosc2==2.7.1\n",
      "bokeh==3.6.1\n",
      "Bottleneck==1.4.2\n",
      "bqplot==0.12.43\n",
      "branca==0.8.0\n",
      "CacheControl==0.14.1\n",
      "cachetools==5.5.0\n",
      "catalogue==2.0.10\n",
      "certifi==2024.8.30\n",
      "cffi==1.17.1\n",
      "chardet==5.2.0\n",
      "charset-normalizer==3.4.0\n",
      "chex==0.1.87\n",
      "clarabel==0.9.0\n",
      "click==8.1.7\n",
      "cloudpathlib==0.20.0\n",
      "cloudpickle==3.1.0\n",
      "cmake==3.30.5\n",
      "cmdstanpy==1.2.4\n",
      "colorcet==3.1.0\n",
      "colorlover==0.3.0\n",
      "colour==0.1.5\n",
      "community==1.0.0b1\n",
      "confection==0.1.5\n",
      "cons==0.4.6\n",
      "contourpy==1.3.1\n",
      "cryptography==43.0.3\n",
      "cuda-python==12.2.1\n",
      "cudf-cu12 @ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-24.10.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
      "cufflinks==0.17.3\n",
      "cupy-cuda12x==12.2.0\n",
      "cvxopt==1.3.2\n",
      "cvxpy==1.5.4\n",
      "cycler==0.12.1\n",
      "cymem==2.0.8\n",
      "Cython==3.0.11\n",
      "dask==2024.10.0\n",
      "datascience==0.17.6\n",
      "datasets==3.1.0\n",
      "db-dtypes==1.3.1\n",
      "dbus-python==1.2.18\n",
      "debugpy==1.8.0\n",
      "decorator==4.4.2\n",
      "defusedxml==0.7.1\n",
      "Deprecated==1.2.15\n",
      "diffusers==0.31.0\n",
      "dill==0.3.8\n",
      "distro==1.9.0\n",
      "dlib==19.24.2\n",
      "dm-tree==0.1.8\n",
      "docker-pycreds==0.4.0\n",
      "docstring_parser==0.16\n",
      "docutils==0.21.2\n",
      "dopamine_rl==4.0.9\n",
      "duckdb==1.1.3\n",
      "earthengine-api==1.2.0\n",
      "easydict==1.13\n",
      "ecos==2.0.14\n",
      "editdistance==0.8.1\n",
      "eerepr==0.0.4\n",
      "einops==0.8.0\n",
      "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\n",
      "entrypoints==0.4\n",
      "et_xmlfile==2.0.0\n",
      "etils==1.10.0\n",
      "etuples==0.3.9\n",
      "eval_type_backport==0.2.0\n",
      "exceptiongroup==1.2.2\n",
      "fastai==2.7.18\n",
      "fastcore==1.7.20\n",
      "fastdownload==0.0.7\n",
      "fastjsonschema==2.20.0\n",
      "fastprogress==1.0.3\n",
      "fastrlock==0.8.2\n",
      "filelock==3.16.1\n",
      "firebase-admin==6.5.0\n",
      "Flask==3.0.3\n",
      "flatbuffers==24.3.25\n",
      "flax==0.8.5\n",
      "folium==0.18.0\n",
      "fonttools==4.55.0\n",
      "frozendict==2.4.6\n",
      "frozenlist==1.5.0\n",
      "fsspec==2024.9.0\n",
      "future==1.0.0\n",
      "gast==0.6.0\n",
      "gcsfs==2024.10.0\n",
      "GDAL==3.6.4\n",
      "gdown==5.2.0\n",
      "geemap==0.35.1\n",
      "gensim==4.3.3\n",
      "geocoder==1.38.1\n",
      "geographiclib==2.0\n",
      "geopandas==1.0.1\n",
      "geopy==2.4.1\n",
      "gin-config==0.5.0\n",
      "gitdb==4.0.11\n",
      "GitPython==3.1.43\n",
      "glob2==0.7\n",
      "google==2.0.3\n",
      "google-ai-generativelanguage==0.6.10\n",
      "google-api-core==2.19.2\n",
      "google-api-python-client==2.151.0\n",
      "google-auth==2.27.0\n",
      "google-auth-httplib2==0.2.0\n",
      "google-auth-oauthlib==1.2.1\n",
      "google-cloud-aiplatform==1.71.1\n",
      "google-cloud-bigquery==3.25.0\n",
      "google-cloud-bigquery-connection==1.16.1\n",
      "google-cloud-bigquery-storage==2.27.0\n",
      "google-cloud-bigtable==2.27.0\n",
      "google-cloud-core==2.4.1\n",
      "google-cloud-datastore==2.20.1\n",
      "google-cloud-firestore==2.19.0\n",
      "google-cloud-functions==1.18.1\n",
      "google-cloud-iam==2.16.1\n",
      "google-cloud-language==2.15.1\n",
      "google-cloud-pubsub==2.27.1\n",
      "google-cloud-resource-manager==1.13.1\n",
      "google-cloud-storage==2.8.0\n",
      "google-cloud-translate==3.17.0\n",
      "google-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz\n",
      "google-crc32c==1.6.0\n",
      "google-generativeai==0.8.3\n",
      "google-pasta==0.2.0\n",
      "google-resumable-media==2.7.2\n",
      "googleapis-common-protos==1.66.0\n",
      "googledrivedownloader==0.4\n",
      "graphviz==0.20.3\n",
      "greenlet==3.1.1\n",
      "grpc-google-iam-v1==0.13.1\n",
      "grpcio==1.68.0\n",
      "grpcio-status==1.62.3\n",
      "gspread==6.0.2\n",
      "gspread-dataframe==3.3.1\n",
      "gym==0.25.2\n",
      "gym-notices==0.0.8\n",
      "h11==0.14.0\n",
      "h5netcdf==1.4.1\n",
      "h5py==3.12.1\n",
      "holidays==0.61\n",
      "holoviews==1.20.0\n",
      "html5lib==1.1\n",
      "httpcore==1.0.7\n",
      "httpimport==1.4.0\n",
      "httplib2==0.22.0\n",
      "httpx==0.27.2\n",
      "huggingface-hub==0.26.2\n",
      "humanize==4.11.0\n",
      "hyperopt==0.2.7\n",
      "ibis-framework==9.2.0\n",
      "idna==3.10\n",
      "imageio==2.36.0\n",
      "imageio-ffmpeg==0.5.1\n",
      "imagesize==1.4.1\n",
      "imbalanced-learn==0.12.4\n",
      "imgaug==0.4.0\n",
      "immutabledict==4.2.1\n",
      "importlib_metadata==8.5.0\n",
      "importlib_resources==6.4.5\n",
      "imutils==0.5.4\n",
      "inflect==7.4.0\n",
      "iniconfig==2.0.0\n",
      "intel-cmplr-lib-ur==2025.0.0\n",
      "intel-openmp==2025.0.0\n",
      "ipyevents==2.0.2\n",
      "ipyfilechooser==0.6.0\n",
      "ipykernel==5.5.6\n",
      "ipyleaflet==0.19.2\n",
      "ipyparallel==8.8.0\n",
      "ipython==7.34.0\n",
      "ipython-genutils==0.2.0\n",
      "ipython-sql==0.5.0\n",
      "ipytree==0.2.2\n",
      "ipywidgets==7.7.1\n",
      "itsdangerous==2.2.0\n",
      "jax==0.4.33\n",
      "jax-cuda12-pjrt==0.4.33\n",
      "jax-cuda12-plugin==0.4.33\n",
      "jaxlib==0.4.33\n",
      "jeepney==0.7.1\n",
      "jellyfish==1.1.0\n",
      "jieba==0.42.1\n",
      "Jinja2==3.1.4\n",
      "jiter==0.7.1\n",
      "joblib==1.4.2\n",
      "jsonpatch==1.33\n",
      "jsonpickle==4.0.0\n",
      "jsonpointer==3.0.0\n",
      "jsonschema==4.23.0\n",
      "jsonschema-specifications==2024.10.1\n",
      "jupyter-client==6.1.12\n",
      "jupyter-console==6.1.0\n",
      "jupyter-leaflet==0.19.2\n",
      "jupyter-server==1.24.0\n",
      "jupyter_core==5.7.2\n",
      "jupyterlab_pygments==0.3.0\n",
      "jupyterlab_widgets==3.0.13\n",
      "kaggle==1.6.17\n",
      "kagglehub==0.3.4\n",
      "keras==3.5.0\n",
      "keyring==23.5.0\n",
      "kiwisolver==1.4.7\n",
      "langchain==0.3.7\n",
      "langchain-core==0.3.19\n",
      "langchain-text-splitters==0.3.2\n",
      "langcodes==3.4.1\n",
      "langsmith==0.1.143\n",
      "language_data==1.2.0\n",
      "launchpadlib==1.10.16\n",
      "lazr.restfulclient==0.14.4\n",
      "lazr.uri==1.0.6\n",
      "lazy_loader==0.4\n",
      "libclang==18.1.1\n",
      "libcudf-cu12 @ https://pypi.nvidia.com/libcudf-cu12/libcudf_cu12-24.10.1-py3-none-manylinux_2_28_x86_64.whl\n",
      "librosa==0.10.2.post1\n",
      "lightgbm==4.5.0\n",
      "linkify-it-py==2.0.3\n",
      "llvmlite==0.43.0\n",
      "locket==1.0.0\n",
      "logical-unification==0.4.6\n",
      "lxml==5.3.0\n",
      "marisa-trie==1.2.1\n",
      "Markdown==3.7\n",
      "markdown-it-py==3.0.0\n",
      "MarkupSafe==3.0.2\n",
      "matplotlib==3.8.0\n",
      "matplotlib-inline==0.1.7\n",
      "matplotlib-venn==1.1.1\n",
      "mdit-py-plugins==0.4.2\n",
      "mdurl==0.1.2\n",
      "miniKanren==1.0.3\n",
      "missingno==0.5.2\n",
      "mistune==3.0.2\n",
      "mizani==0.13.0\n",
      "mkl==2025.0.0\n",
      "ml-dtypes==0.4.1\n",
      "mlxtend==0.23.3\n",
      "more-itertools==10.5.0\n",
      "moviepy==1.0.3\n",
      "mpmath==1.3.0\n",
      "msgpack==1.1.0\n",
      "multidict==6.1.0\n",
      "multipledispatch==1.0.0\n",
      "multiprocess==0.70.16\n",
      "multitasking==0.0.11\n",
      "murmurhash==1.0.10\n",
      "music21==9.3.0\n",
      "namex==0.0.8\n",
      "natsort==8.4.0\n",
      "nbclassic==1.1.0\n",
      "nbclient==0.10.0\n",
      "nbconvert==7.16.4\n",
      "nbformat==5.10.4\n",
      "ndindex==1.9.2\n",
      "nest-asyncio==1.6.0\n",
      "networkx==3.4.2\n",
      "nibabel==5.3.2\n",
      "nltk==3.9.1\n",
      "notebook==6.5.5\n",
      "notebook_shim==0.2.4\n",
      "numba==0.60.0\n",
      "numexpr==2.10.1\n",
      "numpy==1.26.4\n",
      "nvidia-cublas-cu12==12.4.5.8\n",
      "nvidia-cuda-cupti-cu12==12.4.127\n",
      "nvidia-cuda-nvcc-cu12==12.6.77\n",
      "nvidia-cuda-nvrtc-cu12==12.4.127\n",
      "nvidia-cuda-runtime-cu12==12.4.127\n",
      "nvidia-cudnn-cu12==9.1.0.70\n",
      "nvidia-cufft-cu12==11.2.1.3\n",
      "nvidia-curand-cu12==10.3.5.147\n",
      "nvidia-cusolver-cu12==11.6.1.9\n",
      "nvidia-cusparse-cu12==12.3.1.170\n",
      "nvidia-nccl-cu12==2.21.5\n",
      "nvidia-nvjitlink-cu12==12.4.127\n",
      "nvidia-nvtx-cu12==12.4.127\n",
      "nvtx==0.2.10\n",
      "nx-cugraph-cu12 @ https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-24.10.0-py3-none-any.whl\n",
      "oauth2client==4.1.3\n",
      "oauthlib==3.2.2\n",
      "openai==1.54.4\n",
      "opencv-contrib-python==4.10.0.84\n",
      "opencv-python==4.10.0.84\n",
      "opencv-python-headless==4.10.0.84\n",
      "openpyxl==3.1.5\n",
      "opentelemetry-api==1.28.2\n",
      "opentelemetry-sdk==1.28.2\n",
      "opentelemetry-semantic-conventions==0.49b2\n",
      "opt_einsum==3.4.0\n",
      "optax==0.2.4\n",
      "optree==0.13.1\n",
      "orbax-checkpoint==0.6.4\n",
      "orjson==3.10.11\n",
      "osqp==0.6.7.post3\n",
      "packaging==24.2\n",
      "pandas==2.2.2\n",
      "pandas-datareader==0.10.0\n",
      "pandas-gbq==0.24.0\n",
      "pandas-stubs==2.2.2.240909\n",
      "pandocfilters==1.5.1\n",
      "panel==1.5.4\n",
      "param==2.1.1\n",
      "parso==0.8.4\n",
      "parsy==2.1\n",
      "partd==1.4.2\n",
      "pathlib==1.0.1\n",
      "patsy==1.0.1\n",
      "peewee==3.17.8\n",
      "peft==0.13.2\n",
      "pexpect==4.9.0\n",
      "pickleshare==0.7.5\n",
      "pillow==11.0.0\n",
      "platformdirs==4.3.6\n",
      "plotly==5.24.1\n",
      "plotnine==0.14.1\n",
      "pluggy==1.5.0\n",
      "polars==1.9.0\n",
      "pooch==1.8.2\n",
      "portpicker==1.5.2\n",
      "preshed==3.0.9\n",
      "prettytable==3.12.0\n",
      "proglog==0.1.10\n",
      "progressbar2==4.5.0\n",
      "prometheus_client==0.21.0\n",
      "promise==2.3\n",
      "prompt_toolkit==3.0.48\n",
      "propcache==0.2.0\n",
      "prophet==1.1.6\n",
      "proto-plus==1.25.0\n",
      "protobuf==4.25.5\n",
      "psutil==5.9.5\n",
      "psycopg2==2.9.10\n",
      "ptyprocess==0.7.0\n",
      "py-cpuinfo==9.0.0\n",
      "py4j==0.10.9.7\n",
      "pyarrow==17.0.0\n",
      "pyarrow-hotfix==0.6\n",
      "pyasn1==0.6.1\n",
      "pyasn1_modules==0.4.1\n",
      "pycocotools==2.0.8\n",
      "pycparser==2.22\n",
      "pydantic==2.9.2\n",
      "pydantic_core==2.23.4\n",
      "pydata-google-auth==1.8.2\n",
      "pydeck==0.9.1\n",
      "pydot==3.0.2\n",
      "pydotplus==2.0.2\n",
      "PyDrive==1.3.1\n",
      "PyDrive2==1.21.1\n",
      "pyerfa==2.0.1.5\n",
      "pygame==2.6.1\n",
      "pygit2==1.16.0\n",
      "Pygments==2.18.0\n",
      "PyGObject==3.42.1\n",
      "PyJWT==2.10.0\n",
      "pylibcudf-cu12 @ https://pypi.nvidia.com/pylibcudf-cu12/pylibcudf_cu12-24.10.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
      "pylibcugraph-cu12==24.10.0\n",
      "pylibraft-cu12==24.10.0\n",
      "pymc==5.18.2\n",
      "pymystem3==0.2.0\n",
      "pynvjitlink-cu12==0.4.0\n",
      "pyogrio==0.10.0\n",
      "PyOpenGL==3.1.7\n",
      "pyOpenSSL==24.2.1\n",
      "pyparsing==3.2.0\n",
      "pyperclip==1.9.0\n",
      "pyproj==3.7.0\n",
      "pyshp==2.3.1\n",
      "PySocks==1.7.1\n",
      "pyspark==3.5.3\n",
      "pytensor==2.26.3\n",
      "pytest==8.3.3\n",
      "python-apt==0.0.0\n",
      "python-box==7.2.0\n",
      "python-dateutil==2.8.2\n",
      "python-louvain==0.16\n",
      "python-slugify==8.0.4\n",
      "python-utils==3.9.0\n",
      "pytz==2024.2\n",
      "pyviz_comms==3.0.3\n",
      "PyYAML==6.0.2\n",
      "pyzmq==24.0.1\n",
      "qdldl==0.1.7.post4\n",
      "ratelim==0.1.6\n",
      "referencing==0.35.1\n",
      "regex==2024.9.11\n",
      "requests==2.32.3\n",
      "requests-oauthlib==1.3.1\n",
      "requests-toolbelt==1.0.0\n",
      "requirements-parser==0.9.0\n",
      "rich==13.9.4\n",
      "rmm-cu12==24.10.0\n",
      "rpds-py==0.21.0\n",
      "rpy2==3.4.2\n",
      "rsa==4.9\n",
      "safetensors==0.4.5\n",
      "scikit-image==0.24.0\n",
      "scikit-learn==1.5.2\n",
      "scipy==1.13.1\n",
      "scooby==0.10.0\n",
      "scs==3.2.7\n",
      "seaborn==0.13.2\n",
      "SecretStorage==3.3.1\n",
      "Send2Trash==1.8.3\n",
      "sentence-transformers==3.2.1\n",
      "sentencepiece==0.2.0\n",
      "sentry-sdk==2.18.0\n",
      "seqeval==1.2.2\n",
      "setproctitle==1.3.4\n",
      "shap==0.46.0\n",
      "shapely==2.0.6\n",
      "shellingham==1.5.4\n",
      "simple-parsing==0.1.6\n",
      "simpletransformers==0.70.1\n",
      "six==1.16.0\n",
      "sklearn-pandas==2.2.0\n",
      "slicer==0.0.8\n",
      "smart-open==7.0.5\n",
      "smmap==5.0.1\n",
      "sniffio==1.3.1\n",
      "snowballstemmer==2.2.0\n",
      "soundfile==0.12.1\n",
      "soupsieve==2.6\n",
      "soxr==0.5.0.post1\n",
      "spacy==3.7.5\n",
      "spacy-legacy==3.0.12\n",
      "spacy-loggers==1.0.5\n",
      "Sphinx==8.1.3\n",
      "sphinxcontrib-applehelp==2.0.0\n",
      "sphinxcontrib-devhelp==2.0.0\n",
      "sphinxcontrib-htmlhelp==2.1.0\n",
      "sphinxcontrib-jsmath==1.0.1\n",
      "sphinxcontrib-qthelp==2.0.0\n",
      "sphinxcontrib-serializinghtml==2.0.0\n",
      "SQLAlchemy==2.0.36\n",
      "sqlglot==25.1.0\n",
      "sqlparse==0.5.2\n",
      "srsly==2.4.8\n",
      "stanio==0.5.1\n",
      "statsmodels==0.14.4\n",
      "streamlit==1.40.2\n",
      "StrEnum==0.4.15\n",
      "stringzilla==3.10.10\n",
      "sympy==1.13.1\n",
      "tables==3.10.1\n",
      "tabulate==0.9.0\n",
      "tbb==2022.0.0\n",
      "tcmlib==1.2.0\n",
      "tenacity==9.0.0\n",
      "tensorboard==2.17.1\n",
      "tensorboard-data-server==0.7.2\n",
      "tensorboardX==2.6.2.2\n",
      "tensorflow==2.17.1\n",
      "tensorflow-datasets==4.9.7\n",
      "tensorflow-hub==0.16.1\n",
      "tensorflow-io-gcs-filesystem==0.37.1\n",
      "tensorflow-metadata==1.13.1\n",
      "tensorflow-probability==0.24.0\n",
      "tensorstore==0.1.68\n",
      "termcolor==2.5.0\n",
      "terminado==0.18.1\n",
      "text-unidecode==1.3\n",
      "textblob==0.17.1\n",
      "tf-slim==1.1.0\n",
      "tf_keras==2.17.0\n",
      "thinc==8.2.5\n",
      "threadpoolctl==3.5.0\n",
      "tifffile==2024.9.20\n",
      "timm==1.0.11\n",
      "tinycss2==1.4.0\n",
      "tokenizers==0.20.3\n",
      "toml==0.10.2\n",
      "tomli==2.1.0\n",
      "toolz==0.12.1\n",
      "torch==2.5.1\n",
      "torchaudio @ https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl\n",
      "torchsummary==1.5.1\n",
      "torchvision @ https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp310-cp310-linux_x86_64.whl\n",
      "tornado==6.3.3\n",
      "tqdm==4.66.6\n",
      "traitlets==5.7.1\n",
      "traittypes==0.2.1\n",
      "transformers==4.46.3\n",
      "triton==3.1.0\n",
      "tweepy==4.14.0\n",
      "typeguard==4.4.1\n",
      "typer==0.13.0\n",
      "types-pytz==2024.2.0.20241003\n",
      "types-setuptools==75.5.0.20241122\n",
      "typing_extensions==4.12.2\n",
      "tzdata==2024.2\n",
      "tzlocal==5.2\n",
      "uc-micro-py==1.0.3\n",
      "umf==0.9.0\n",
      "uritemplate==4.1.1\n",
      "urllib3==2.2.3\n",
      "vega-datasets==0.9.0\n",
      "wadllib==1.3.6\n",
      "wandb==0.18.7\n",
      "wasabi==1.1.3\n",
      "watchdog==6.0.0\n",
      "wcwidth==0.2.13\n",
      "weasel==0.4.1\n",
      "webcolors==24.11.1\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.8.0\n",
      "Werkzeug==3.1.3\n",
      "widgetsnbextension==3.6.10\n",
      "wordcloud==1.9.4\n",
      "wrapt==1.16.0\n",
      "xarray==2024.10.0\n",
      "xarray-einstats==0.8.0\n",
      "xgboost==2.1.2\n",
      "xlrd==2.0.1\n",
      "xxhash==3.5.0\n",
      "xyzservices==2024.9.0\n",
      "yarl==1.17.2\n",
      "yellowbrick==1.5\n",
      "yfinance==0.2.49\n",
      "zipp==3.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMDtAY9WuHCHnY6rsyN13J8",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
